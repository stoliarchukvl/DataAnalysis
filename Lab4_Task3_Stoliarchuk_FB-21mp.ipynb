{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eeeebfbf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\r\n",
      "      - Validating: \u001b[32mOK\u001b[0m\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-25 16:02:25.713097: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-25 16:02:26.290551: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-25 16:02:26.290590: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-25 16:02:28.495199: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-25 16:02:28.495422: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-25 16:02:28.495435: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# Task 3\n",
    "!jupyter nbextension enable --py widgetsnbextension\n",
    "import codecs\n",
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "from ipywidgets import FloatProgress\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9aac612",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "2023-01-25 16:02:47.101644: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-01-25 16:02:47.102380: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-01-25 16:02:47.102469: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (kali): /proc/driver/nvidia/version does not exist\n",
      "2023-01-25 16:02:47.103911: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-25 16:02:47.308038: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 93763584 exceeds 10% of free system memory.\n",
      "2023-01-25 16:02:47.748098: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 93763584 exceeds 10% of free system memory.\n",
      "2023-01-25 16:02:47.769537: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 93763584 exceeds 10% of free system memory.\n",
      "2023-01-25 16:02:50.166090: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 93763584 exceeds 10% of free system memory.\n",
      "2023-01-25 16:02:50.244411: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 93763584 exceeds 10% of free system memory.\n",
      "All model checkpoint layers were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the layers of TFDistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline('sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "697dcf4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011793136596679688,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 27,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 473,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f0a7b7407b04dd181c353a1d3888e3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/473 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011309385299682617,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 27,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 260894952,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d02f4c5aa7448e2808b04e631d398e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/261M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-cased-distilled-squad were not used when initializing TFDistilBertForQuestionAnswering: ['dropout_19']\n",
      "- This IS expected if you are initializing TFDistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-cased-distilled-squad and are newly initialized: ['dropout_39']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011657476425170898,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 27,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 29,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7a3f122f3b94ba6903d726e48f6df8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011342048645019531,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 27,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 213450,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c1c980d161a4b7aa0d9344ec74a6b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01649951934814453,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 27,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 435797,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80685af69ada4183984d2bc7770e230b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.8583741784095764, 'start': 0, 'end': 9, 'answer': 'Definetly'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_qusetion_answering = pipeline('question-answering')\n",
    "nlp_qusetion_answering(context='Definetly', question='Am I a good student?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43b31814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9955266118049622}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_one = 'Vladislav Stoliarchuk'\n",
    "classifier(text_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5257717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9590654373168945}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_two = 'Ukraine)'\n",
    "classifier(text_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2f31dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9895161390304565}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_three = 'FB-21mp'\n",
    "classifier(text_three)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "949f90a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.5971269011497498}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_four = 'IPT'\n",
    "classifier(text_four)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72d5a365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9974727034568787}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_five = 'Ukraine will easy beat russia'\n",
    "classifier(text_five)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0238ace2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english were not used when initializing TFDistilBertForSequenceClassification: ['dropout_19']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english and are newly initialized: ['dropout_39']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fc757de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 19163, 19834, 2358, 10893, 2906, 26516, 102], [101, 5924, 1007, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Input = tokenizer([text_one, text_two])\n",
    "Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f55b9807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(2, 8), dtype=int32, numpy=\n",
       "array([[  101, 19163, 19834,  2358, 10893,  2906, 26516,   102],\n",
       "       [  101,  5924,  1007,   102,     0,     0,     0,     0]],\n",
       "      dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(2, 8), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 0, 0, 0, 0]], dtype=int32)>}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Input_with_padding = tokenizer([text_one, text_two], padding = True, truncation = True, max_length = 256, return_tensors=\"tf\")\n",
    "Input_with_padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "053d925c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TFSequenceClassifierOutput(loss=None, logits=<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[-2.654481 ,  2.750637 ],\n",
       "       [-1.5043954,  1.6495923]], dtype=float32)>, hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Output = model(Input_with_padding)\n",
    "Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5366c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[0.00447342, 0.9955266 ],\n",
       "       [0.04093444, 0.95906556]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = tf.nn.softmax(Output[0], axis=-1)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d494b274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 19163, 19834, 2358, 10893, 2906, 26516, 102], [101, 5924, 1007, 102], [101, 1042, 2497, 1011, 2538, 8737, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Input = tokenizer([text_one, text_two, text_three])\n",
    "Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "193f0292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(3, 8), dtype=int32, numpy=\n",
       "array([[  101, 19163, 19834,  2358, 10893,  2906, 26516,   102],\n",
       "       [  101,  5924,  1007,   102,     0,     0,     0,     0],\n",
       "       [  101,  1042,  2497,  1011,  2538,  8737,   102,     0]],\n",
       "      dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(3, 8), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 0]], dtype=int32)>}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Input_with_padding = tokenizer([text_one, text_two, text_three], padding = True, truncation = True, max_length = 256, return_tensors=\"tf\")\n",
    "Input_with_padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2e46888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TFSequenceClassifierOutput(loss=None, logits=<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[-2.654481 ,  2.750637 ],\n",
       "       [-1.5043954,  1.6495922],\n",
       "       [ 2.4833713, -2.0640035]], dtype=float32)>, hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Output = model(Input_with_padding)\n",
    "Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "625c7aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[0.00447342, 0.9955266 ],\n",
       "       [0.04093445, 0.95906556],\n",
       "       [0.98951614, 0.01048391]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = tf.nn.softmax(Outputs[0], axis=-1)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7bae0eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 19163, 19834, 2358, 10893, 2906, 26516, 102], [101, 5924, 1007, 102], [101, 1042, 2497, 1011, 2538, 8737, 102], [101, 12997, 2102, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Input = tokenizer([text_one, text_two, text_three, text_four])\n",
    "Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf6330a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(4, 8), dtype=int32, numpy=\n",
       "array([[  101, 19163, 19834,  2358, 10893,  2906, 26516,   102],\n",
       "       [  101,  5924,  1007,   102,     0,     0,     0,     0],\n",
       "       [  101,  1042,  2497,  1011,  2538,  8737,   102,     0],\n",
       "       [  101, 12997,  2102,   102,     0,     0,     0,     0]],\n",
       "      dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(4, 8), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 0],\n",
       "       [1, 1, 1, 1, 0, 0, 0, 0]], dtype=int32)>}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Input_with_padding = tokenizer([text_one, text_two, text_three, text_four], padding = True, truncation = True, max_length = 256, return_tensors=\"tf\")\n",
    "Input_with_padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "445ae9b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TFSequenceClassifierOutput(loss=None, logits=<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
       "array([[-2.6544807 ,  2.750637  ],\n",
       "       [-1.5043954 ,  1.6495923 ],\n",
       "       [ 2.4833713 , -2.0640035 ],\n",
       "       [ 0.3297074 , -0.06381101]], dtype=float32)>, hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Output = model(Input_with_padding)\n",
    "Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88a161c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
       "array([[0.00447342, 0.9955266 ],\n",
       "       [0.04093444, 0.95906556],\n",
       "       [0.98951614, 0.01048391],\n",
       "       [0.5971294 , 0.4028706 ]], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = tf.nn.softmax(Output[0], axis=-1)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82409762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 19163, 19834, 2358, 10893, 2906, 26516, 102], [101, 5924, 1007, 102], [101, 1042, 2497, 1011, 2538, 8737, 102], [101, 12997, 2102, 102], [101, 5924, 2097, 3733, 3786, 3607, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Input = tokenizer([text_one, text_two, text_three, text_four, text_five])\n",
    "Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9dfbac00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(5, 8), dtype=int32, numpy=\n",
       "array([[  101, 19163, 19834,  2358, 10893,  2906, 26516,   102],\n",
       "       [  101,  5924,  1007,   102,     0,     0,     0,     0],\n",
       "       [  101,  1042,  2497,  1011,  2538,  8737,   102,     0],\n",
       "       [  101, 12997,  2102,   102,     0,     0,     0,     0],\n",
       "       [  101,  5924,  2097,  3733,  3786,  3607,   102,     0]],\n",
       "      dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(5, 8), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 0],\n",
       "       [1, 1, 1, 1, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 0]], dtype=int32)>}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Input_with_padding = tokenizer([text_one, text_two, text_three, text_four, text_five], padding = True, truncation = True, max_length = 256, return_tensors=\"tf\")\n",
    "Input_with_padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c27744dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TFSequenceClassifierOutput(loss=None, logits=<tf.Tensor: shape=(5, 2), dtype=float32, numpy=\n",
       "array([[-2.6544807 ,  2.750637  ],\n",
       "       [-1.5043954 ,  1.6495923 ],\n",
       "       [ 2.4833713 , -2.0640035 ],\n",
       "       [ 0.3297074 , -0.06381101],\n",
       "       [-2.9337354 ,  3.0443406 ]], dtype=float32)>, hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Output = model(Input_with_padding)\n",
    "Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2653c522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 2), dtype=float32, numpy=\n",
       "array([[0.00447342, 0.9955266 ],\n",
       "       [0.04093444, 0.95906556],\n",
       "       [0.98951614, 0.01048391],\n",
       "       [0.5971294 , 0.4028706 ],\n",
       "       [0.00252729, 0.9974727 ]], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = tf.nn.softmax(Output[0], axis=-1)\n",
    "prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
